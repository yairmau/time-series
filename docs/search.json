[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Time Series Analysis",
    "section": "",
    "text": "This is a work in progress."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1Â  Introduction",
    "section": "",
    "text": "See Knuth (1984) for additional discussion of literate programming.\n\n\n\n\nKnuth, Donald E. 1984. â€œLiterate Programming.â€ Comput. J. 27 (2): 97â€“111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "2Â  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever."
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. â€œLiterate Programming.â€ Comput.\nJ. 27 (2): 97â€“111. https://doi.org/10.1093/comjnl/27.2.97."
  },
  {
    "objectID": "convolution/index.html",
    "href": "convolution/index.html",
    "title": "1Â  Convolution",
    "section": "",
    "text": "This is the temperature for Tel Aviv, between 2 and 5 of January 2022. Data is in intervals of 10 minutes, and was downloaded from the Israel Meteorological Service.\nWe see that the temperature curve has a rough profile. Can we find ways of getting smoother curves?"
  },
  {
    "objectID": "convolution/index.html#convolution",
    "href": "convolution/index.html#convolution",
    "title": "1Â  Convolution",
    "section": "1.1 Convolution",
    "text": "1.1 Convolution\nConvolution is a fancy word for averaging a time series using a running window. We will use the terms convolution, running average, and rolling average interchangeably. See the animation below. We take all temperature values inside a window of width 500 minutes (51 points), and average them with equal weights. The weights profile is called kernel.\n\n\nThe pink curve is much smoother than the original! However, the running average cannot describe sharp temperature changes. If we decrease the window width to 200 minutes (21 points), we get the following result.\n\n\nThere is a tradeoff between the smoothness of a curve, and its ability to describe sharp temporal changes."
  },
  {
    "objectID": "convolution/index.html#kernels",
    "href": "convolution/index.html#kernels",
    "title": "1Â  Convolution",
    "section": "1.2 Kernels",
    "text": "1.2 Kernels\nWe can modify our running average, so that values closer to the center of the window have higher weights, and those further away count less. This is achieved by changing the weight profile, or the shape of the kernel. We see below the result of a running average using a triangular window of base 500 minutes (51 points).\n\n\nThings can get as fancy as we want. Instead of a triangular kernel, which has sharp edges, we can choose a smoother gaussian kernel, see the difference below. We used a gaussian kernel with 60-minute standard deviation (the window in the animation is 4 standard deviations wide)."
  },
  {
    "objectID": "convolution/index.html#math",
    "href": "convolution/index.html#math",
    "title": "1Â  Convolution",
    "section": "1.3 Math",
    "text": "1.3 Math\nThe definition of a convolution between signal \\(f(t)\\) and kernel \\(k(t)\\) is\n\\[\n(f * k)(t) = \\int f(\\tau)k(t-\\tau)d\\tau.\n\\]\nThe expression \\(f*k\\) denotes the convolution of these two functions. The argument of \\(k\\) is \\(t-\\tau\\), meaning that the kernel runs from left to right (as \\(t\\) does), and at every point the two signals (\\(f\\) and \\(k\\)) are multiplied together. It is the product of the signal with the weight function \\(k\\) that gives us an average. Because of \\(-\\tau\\), the kernel is flipped backwards, but this has no effect to symmetric kernels, like to ones in the examples above. Finally, the actual running average is not the convolution, but\n\\[\n\\frac{(f * k)(t)}{\\displaystyle \\int k(t)dt}.\n\\]\nWhenever the integral of the kernel is 1, then the convolution will be identical with the running average."
  },
  {
    "objectID": "convolution/index.html#numerics",
    "href": "convolution/index.html#numerics",
    "title": "1Â  Convolution",
    "section": "1.4 Numerics",
    "text": "1.4 Numerics\nRunning averages are very common tools in time-series analysis. The pandas package makes life quite simple. For example, in order to calculate the running average of temperature using a rectangular kernel, one writes\ndf['temperature'].rolling(window='20', center=True).mean()\n\nwindow=20 means that the width of the window is 20 points. Pandas lets us define a window width in time units, for example, window='120min'.\ncenter=True is needed in order to assign the result of averaging to the center of the window. Make it False and see what happens.\nmean() is the actual calculation, the average of temperature over the window. The rolling part does not compute anything, it just creates a moving window, and we are free to calculate whatever we want. Try to calculate the standard deviation or the maximum, for example.\n\nIt is implicit in the command above a â€œrectangularâ€ kernel. What if we want other shapes?\n\n1.4.1 Gaussian\n(\ndf['temperature'].rolling(window=window_width,\n                          center=True,\n                          win_type=\"gaussian\")\n                 .mean(std=std_gaussian)\n)\nwhere * window_width is an integer, number of points in your window * std_gaussian is the standard deviation of your gaussian, measured in sample points, not time!\nFor instance, if we have measurements every 10 minutes, and our window width is 500 minutes, then window_width = 500/10 + 1 (first and last included). If we want a standard deviation of 60 minutes, then std_gaussian = 6. The gaussian kernel will look like this:\n\nYou can take a look at various options for kernel shapes here, provided by the scipy package. The graph above was achieved by running:\ng = scipy.signal.gaussian(window_width, std)\nplt.plot(g)\n\n\n1.4.2 Triangular\nSame idea as gaussian, but simpler, because we donâ€™t need to think about standard deviation.\n(\ndf['temperature'].rolling(window=window_width,\n                          center=True,\n                          win_type=\"triang\")\n                 .mean()\n)"
  },
  {
    "objectID": "convolution/index.html#which-window-shape-and-width-to-choose",
    "href": "convolution/index.html#which-window-shape-and-width-to-choose",
    "title": "1Â  Convolution",
    "section": "1.5 ðŸ¤·â€â™‚ï¸ Which window shape and width to choose?",
    "text": "1.5 ðŸ¤·â€â™‚ï¸ Which window shape and width to choose?\nSorry, there is not definite answer hereâ€¦ It really depends on your data and what you need to do with it. See below a comparison of all examples in the videos above."
  },
  {
    "objectID": "seasonal-decomposition/seasonal-decomposition.html",
    "href": "seasonal-decomposition/seasonal-decomposition.html",
    "title": "3Â  Seasonal Decomposition",
    "section": "",
    "text": "import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom pandas.plotting import register_matplotlib_converters\nregister_matplotlib_converters()  # datetime converter for a matplotlib\nimport seaborn as sns\nsns.set(style=\"ticks\", font_scale=1.5)\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nimport matplotlib.dates as mdates\nfrom matplotlib.dates import DateFormatter"
  },
  {
    "objectID": "seasonal-decomposition/seasonal-decomposition.html#decompose-data",
    "href": "seasonal-decomposition/seasonal-decomposition.html#decompose-data",
    "title": "3Â  Seasonal Decomposition",
    "section": "4.1 decompose data",
    "text": "4.1 decompose data\nseasonal_decompose returns an object with four components:\n\nobserved: \\(Y(t)\\)\ntrend: \\(T(t)\\)\nseasonal: \\(S(t)\\)\nresid: \\(e(t)\\)\n\nAdditive model: \\[\nY(t) = T(t) + S(t) + e(t)\n\\]\nMultiplicative model: \\[\nY(t) = T(t) \\times S(t) \\times e(t)\n\\]\n\n4.1.0.1 Interlude\nlearn how to use zip in a loop\n\nletters = ['a', 'b', 'c', 'd', 'e']\nnumbers = [1, 2, 3, 4, 5]\n# zip let's us iterate over to lists at the same time\nfor l, n in zip(letters, numbers):\n    print(f\"{l} = {n}\")\n\na = 1\nb = 2\nc = 3\nd = 4\ne = 5\n\n\nPlot each component separately.\n\n# %matplotlib widget\n\nfig, ax = plt.subplots(4, 1, figsize=(8,6), sharex=True)\ndecomposed_m = seasonal_decompose(df['co2'], model='multiplicative')\ndecomposed_a = seasonal_decompose(df['co2'], model='additive')\ndecomposed = decomposed_m\npos = (0.5, 0.9)\ncomponents =[\"observed\", \"trend\", \"seasonal\", \"resid\"]\ncolors = [\"tab:blue\", \"tab:orange\", \"tab:green\", \"tab:red\"]\nfor axx, component, color in zip(ax, components, colors):\n    data = getattr(decomposed, component)\n    axx.plot(data, color=color)\n    axx.text(*pos, component, bbox=dict(facecolor='white', alpha=0.8),\n           transform=axx.transAxes, ha='center', va='top')\n\n\n\n\n\n# %matplotlib widget\n\ndecomposed = decomposed_m\n\nfig, ax = plt.subplots(1, 2, figsize=(10,6))\nax[0].plot(df['co2'], color=\"tab:blue\", label=\"observed\")\nax[0].plot(decomposed.trend * decomposed.resid, color=\"tab:orange\", label=\"trend*resid\")\nax[0].plot(decomposed.trend * decomposed.seasonal, color=\"tab:red\", label=\"trend*seasonal\")\nax[0].plot(decomposed.trend, color=\"black\", label=\"trend\")\nax[0].set(ylabel=\"CO$_2$ concentration (ppm)\",\n          title=\"Mauna Loa CO$_2$ concentration\")\nax[0].legend(frameon=False)\n\nstart = \"2000-01-01\"\nend = \"2003-01-01\"\nzoom = slice(start, end)\nax[1].plot(df.loc[zoom, 'co2'], color=\"tab:blue\", label=\"observed\")\nax[1].plot((decomposed.trend * decomposed.resid)[zoom], color=\"tab:orange\", label=\"trend*resid\")\nax[1].plot((decomposed.trend * decomposed.seasonal)[zoom], color=\"tab:red\", label=\"trend*seasonal\")\nax[1].plot(decomposed.trend[zoom], color=\"black\", label=\"trend\")\ndate_form = DateFormatter(\"%Y\")\nax[1].xaxis.set_major_formatter(date_form)\nax[1].xaxis.set_major_locator(mdates.YearLocator(1))\nax[1].set_title(\"Components, 2000--2003\");"
  },
  {
    "objectID": "first-steps/first-steps.html",
    "href": "first-steps/first-steps.html",
    "title": "1Â  First Steps â€” basic time series analysis",
    "section": "",
    "text": "Import packages. If you donâ€™t have a certain package, e.g.Â â€˜newpackageâ€™, just type\npip install newpackage\nThis is how you download data from Thingspeak\nYou can load the data using Pandas. Here we create a â€œdataframeâ€, which is a fancy name for a table."
  },
  {
    "objectID": "first-steps/first-steps.html#nan-missing-data-outliers",
    "href": "first-steps/first-steps.html#nan-missing-data-outliers",
    "title": "1Â  First Steps â€” basic time series analysis",
    "section": "1.1 NaN, Missing data, Outliers",
    "text": "1.1 NaN, Missing data, Outliers\n\n# %matplotlib widget\n\nstart = \"2022-05-03 12:00:00\"\nend = \"2022-05-06 00:00:00\"\n\nfig, ax = plt.subplots(1, figsize=(8,4))\n\n# plot using pandas' plot method\ndf.loc[start:end, 'T2'].plot(ax=ax,\n                             linestyle='-',\n                             marker='o',\n                             color=\"tab:blue\",\n                             label=\"data\")\n\n# annotate examples here:\n# https://jakevdp.github.io/PythonDataScienceHandbook/04.09-text-and-annotation.html\nax.annotate(\"NaN\",                             # text to write, if nothing, then \"\"\n            xy=('2022-05-03 20:30:00', 25),    # (x,y coordinates for the tip of the arrow)\n            xycoords='data',                   # xy as 'data' coordinates\n            xytext=(-20, 60),                  # xy coordinates for the text\n            textcoords='offset points',        # xytext relative to xy\n            arrowprops=dict(arrowstyle=\"->\")   # pretty arrow\n           )\nax.annotate(\"outlier\",\n            xy=('2022-05-03 22:30:00', 85),\n            xycoords='data',\n            xytext=(40, -20),\n            textcoords='offset points',\n            arrowprops=dict(arrowstyle=\"->\")\n           )\nax.annotate(\"missing rows\",\n            xy=('2022-05-05 00:00:00', 25),\n            xycoords='data',\n            xytext=(0, 40),\n            textcoords='offset points',\n            arrowprops=dict(arrowstyle=\"->\")\n           )\n\nax.xaxis.set_major_formatter(mdates.DateFormatter('%d %b, %H:00'))\nplt.gcf().autofmt_xdate()\nax.set(xlabel=\"\",\n       ylabel=\"Temperature (deg C)\")\n\n[Text(0.5, 0, ''), Text(0, 0.5, 'Temperature (deg C)')]\n\n\n\n\n\nThe arrows (annotate) work because the plot was\ndf['column'].plot()\nIf you use the usual\nax.plot(df['column'])\nthen you matplotlib will not understand timestamps as x-positions. In this case follow the instructions below.\n\n# %matplotlib widget\n\nstart = \"2022-05-03 12:00:00\"\nend = \"2022-05-06 00:00:00\"\n\nfig, ax = plt.subplots(1, figsize=(8,4))\n\nax.plot(df.loc[start:end, 'T2'], linestyle='-', marker='o', color=\"tab:blue\", label=\"data\")\n\nt_nan = '2022-05-03 20:30:00'\nx_nan = mdates.date2num(dt.datetime.strptime(t_nan, \"%Y-%m-%d %H:%M:%S\"))\nax.annotate(\"NaN\",\n            xy=(x_nan, 25),\n            xycoords='data',\n            xytext=(-20, 60),\n            textcoords='offset points',\n            arrowprops=dict(arrowstyle=\"->\")\n           )\nt_outlier = '2022-05-03 22:30:00'\nx_outlier = mdates.date2num(dt.datetime.strptime(t_outlier, \"%Y-%m-%d %H:%M:%S\"))\nax.annotate(\"outlier\",\n            xy=(x_outlier, 85),\n            xycoords='data',\n            xytext=(40, -20),\n            textcoords='offset points',\n            arrowprops=dict(arrowstyle=\"->\")\n           )\nt_missing = '2022-05-05 00:00:00'\nx_missing = mdates.date2num(dt.datetime.strptime(t_missing, \"%Y-%m-%d %H:%M:%S\"))\nax.annotate(\"missing rows\",\n            xy=(x_missing, 25),\n            xycoords='data',\n            xytext=(0, 40),\n            textcoords='offset points',\n            arrowprops=dict(arrowstyle=\"->\")\n           )\n# code for hours, days, etc\n# https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes\nax.xaxis.set_major_formatter(mdates.DateFormatter('%d %b, %H:00'))\nplt.gcf().autofmt_xdate()\nax.set(xlabel=\"\",\n       ylabel=\"Temperature (deg C)\")\n\n[Text(0.5, 0, ''), Text(0, 0.5, 'Temperature (deg C)')]\n\n\n\n\n\n\n# %matplotlib widget\n\nfig, ax = plt.subplots(1, figsize=(8,4))\n\ndelta_index = (df.index.to_series().diff() / pd.Timedelta('1 sec') ).values\nax.plot(delta_index)\nax.set(ylim=[0, 100],\n       xlabel=\"running index\",\n       ylabel=r\"$\\Delta t$ (s)\",\n       title=\"Time difference between consecutive rows\")\n\n[(0.0, 100.0),\n Text(0.5, 0, 'running index'),\n Text(0, 0.5, '$\\\\Delta t$ (s)'),\n Text(0.5, 1.0, 'Time difference between consecutive rows')]"
  },
  {
    "objectID": "first-steps/first-steps.html#resample",
    "href": "first-steps/first-steps.html#resample",
    "title": "1Â  First Steps â€” basic time series analysis",
    "section": "1.2 Resample",
    "text": "1.2 Resample\n\n1.2.1 Downsampling\n\n# %matplotlib widget\n\nfig, ax = plt.subplots(1, figsize=(8,4))\n\n# Downsample to spaced out data points. Change the number below, see what happens.\nwindow_size = '15min'\ndf_resampled = (df['T2'].resample(window_size)  # resample doesn't do anything yet, just divides data into buckets\n                        .mean()                 # this is where stuff happens. you can also choose \"sum\", \"max\", etc\n               )\n# optional, add half a window size to timestamp\ndf_resampled.index = df_resampled.index + to_offset(window_size) / 2\n\nax.plot(df['T2'], color=\"tab:blue\", label=\"original data\")\nax.plot(df_resampled, marker='x', color=\"tab:orange\", zorder=-1,\n        label=f\"resampled {window_size} data\")\nax.legend()\n\nax.set(xlabel=\"time\",\n       ylabel=\"temperature (deg C)\")\n\n[Text(0.5, 0, 'time'), Text(0, 0.5, 'temperature (deg C)')]\n\n\n\n\n\n\n\n1.2.2 Filling missing data\n\n# %matplotlib widget\n\nfig, ax = plt.subplots(1, figsize=(8,4))\n\n# see options for interpolation methods here:\n# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.interpolate.html\ndf_interpolated1 = df_resampled.interpolate(method='time')\ndf_interpolated2 = df_resampled.interpolate(method='nearest')\n\nax.plot(df_resampled, color=\"tab:orange\", label=\"resampled\")\nax.plot(df_interpolated1, '.', color=\"tab:purple\", zorder=-1,\n        label=f\"time-interpolated\")\nax.plot(df_interpolated2, '.', color=\"tab:cyan\", zorder=-2,\n        label=f\"nearest-interpolated\")\nax.legend()\n\nax.set(xlabel=\"time\",\n       ylabel=\"temperature (deg C)\")\n\n[Text(0.5, 0, 'time'), Text(0, 0.5, 'temperature (deg C)')]"
  },
  {
    "objectID": "first-steps/first-steps.html#smoothing-noisy-data",
    "href": "first-steps/first-steps.html#smoothing-noisy-data",
    "title": "1Â  First Steps â€” basic time series analysis",
    "section": "1.3 Smoothing noisy data",
    "text": "1.3 Smoothing noisy data\nLetâ€™s first download data from a different project.\n\nfilename2 = \"test_peleg.csv\"\n# if file is not there, go fetch it from thingspeak\nif not os.path.isfile(filename2):\n    # define what to download\n    channels = \"1708067\"\n    fields = \"1,2,3,4,5\"\n    minutes = \"30\"\n\n    # https://www.mathworks.com/help/thingspeak/readdata.html\n    # format YYYY-MM-DD%20HH:NN:SS\n    start = \"2022-05-15%2000:00:00\"\n    end = \"2022-05-25%2000:00:00\"\n\n    # download using Thingspeak's API\n    # url = f\"https://api.thingspeak.com/channels/{channels}/fields/{fields}.csv?minutes={minutes}\"\n    url = f\"https://api.thingspeak.com/channels/{channels}/fields/{fields}.csv?start={start}&end={end}\"\n    data = urllib.request.urlopen(url)\n    d = data.read()\n\n    # save data to csv\n    file = open(filename2, \"w\")\n    file.write(d.decode('UTF-8'))\n    file.close()\n\n\n# load data\ndf = pd.read_csv(filename2)\n# rename columns\ndf = df.rename(columns={\"created_at\": \"timestamp\",\n                        \"field1\": \"T\",\n                        \"field2\": \"Tw\",\n                        \"field3\": \"RH\",\n                        \"field4\": \"VPD\",\n                        \"field5\": \"dist\",\n                        })\n# set timestamp as index\ndf['timestamp'] = pd.to_datetime(df['timestamp'])\ndf = df.set_index('timestamp')\n\n\ndf\n\n\n\n\n\n  \n    \n      \n      entry_id\n      T\n      Tw\n      RH\n      VPD\n      dist\n    \n    \n      timestamp\n      \n      \n      \n      \n      \n      \n    \n  \n  \n    \n      2022-05-18 20:09:31+00:00\n      24716\n      23.85\n      23.3125\n      65.32\n      1.02532\n      7.208\n    \n    \n      2022-05-18 20:10:32+00:00\n      24717\n      23.88\n      23.2500\n      65.32\n      1.02717\n      7.208\n    \n    \n      2022-05-18 20:11:33+00:00\n      24718\n      23.90\n      23.2500\n      65.23\n      1.03107\n      7.276\n    \n    \n      2022-05-18 20:12:33+00:00\n      24719\n      23.90\n      23.2500\n      65.19\n      1.03226\n      7.208\n    \n    \n      2022-05-18 20:13:34+00:00\n      24720\n      23.89\n      23.2500\n      65.15\n      1.03282\n      7.633\n    \n    \n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n      ...\n    \n    \n      2022-05-24 12:18:35+00:00\n      32711\n      27.47\n      26.1250\n      47.49\n      1.92397\n      8.925\n    \n    \n      2022-05-24 12:19:36+00:00\n      32712\n      27.47\n      26.1250\n      47.62\n      1.91921\n      8.925\n    \n    \n      2022-05-24 12:20:39+00:00\n      32713\n      27.47\n      26.1250\n      47.96\n      1.90675\n      8.925\n    \n    \n      2022-05-24 12:21:40+00:00\n      32714\n      27.47\n      26.1875\n      47.75\n      1.91444\n      8.925\n    \n    \n      2022-05-24 12:22:41+00:00\n      32715\n      27.49\n      26.1875\n      47.94\n      1.90971\n      8.925\n    \n  \n\n8000 rows Ã— 6 columns"
  },
  {
    "objectID": "first-steps/first-steps.html#smoothing-noisy-data-1",
    "href": "first-steps/first-steps.html#smoothing-noisy-data-1",
    "title": "1Â  First Steps â€” basic time series analysis",
    "section": "1.4 Smoothing noisy data",
    "text": "1.4 Smoothing noisy data\n\n# %matplotlib widget\n\nfig, ax = plt.subplots(1, figsize=(8,4))\n\nax.plot(df['RH'], '.')\n# add labels and title\nax.set(xlabel = \"time\",\n       ylabel = \"RH (%)\",\n       title = \"Relative Humidity\")\n# makes slanted dates\nplt.gcf().autofmt_xdate()  \n\n\n\n\n\n1.4.1 Moving average and SavGol\n\n# %matplotlib widget\n\nfig, ax = plt.subplots(1, figsize=(8,4))\n\n# apply a rolling average of size \"window_size\",\n# it can be either by number of points, or by window time\n# window_size = 30  # number of measurements\nwindow_size = '120min'  # minutes\nRH_smooth = df['RH'].rolling(window_size, center=True).mean().to_frame()\nRH_smooth.rename(columns={'RH': 'rolling_avg'}, inplace=True)\n\nRH_smooth['SG'] = savgol_filter(df['RH'], window_length=121, polyorder=2)\n\nax.plot(df['RH'], color=\"tab:blue\", label=\"data\")\nax.plot(RH_smooth['rolling_avg'], color=\"tab:orange\", label=\"moving average\")\nax.plot(RH_smooth['SG'], color=\"tab:red\", label=\"Savitzky-Golay filter\")\n# add labels and title\nax.set(xlabel = \"time\",\n       ylabel = \"RH (%)\",\n       title = \"Relative Humidity\")\n# makes slanted dates\nplt.gcf().autofmt_xdate()\nax.legend()\n\n<matplotlib.legend.Legend at 0x7fe6a0525730>\n\n\n\n\n\nHow does moving average work?\n\nHow does the Savitzkyâ€“Golay filter work?"
  }
]